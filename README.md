# Integrated-Marketing-Analytics
Market Spend Optimization using Machine Learning

#Requirements
matplotlib==3.7.1
numpy==1.20.0
pandas==1.2.4
scikit-learn==0.23.2
xgboost==1.6.2
lightgbm==3.3.2

#Deployment

# By Eric Chemhere Version 1.0
#  Resilient Distributed Datasets
Resilient Distributed Datasets (RDD) is a fundamental data structure of Spark. It is an immutable distributed collection of objects. Each dataset in RDD is divided into logical partitions, which may be computed on different nodes of the cluster.

# Ways Of Data Processing in spark
- In-Memory Computation
- Batch Data Processing

    
# Distribution 
Distribution of data across multiple nodes

## Architecture of Directed Acyclic Graph

- DAG Scheduler
- Task Sheduler
- Stages
- Executer

# Operations In Spark
- Transformation
- Action

 
# Code Description
    File Name : pyspark.ipynb , xxx .ipynb, pyspark.py and Pearson .py
    DataSets : Marketing_Data.csv
    File Description : Implement Transformations and Actions Functions on RDD
    
## Steps to Run
There are two ways to execute the end to end flow.
- Command Prompt => python script
- spark_path spark-submit file_path
- spark_path => <path_to_spark>>
- file_path => <path_to_file>
- Data file path is same as script file path

eg. <C:\Users\ericc\admin\Desktop\spark\bin>spark-submit C:\Users\ericc\admin\Desktop\RDDs\pyspark.py>


- IPython

### Modular code
- Create virtualenv
- Install requirements `pip install -r requirements.txt`
- Run Code `python pyspark.py`
- Run Code `python Pearson .py`
- Check output for all the visualization
### IPython
Follow the instructions in the notebook `.ipynb`
Follow the instructions in the notebook ` .ipynb`

 
